{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fingerprint Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from ogb.graphproppred import DglGraphPropPredDataset, Evaluator\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fingerprint\n",
    "from gtrick import ogb2fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graph_pred(args):\n",
    "    dataset = DglGraphPropPredDataset(\n",
    "        name=args.dataset, root=args.dataset_path)\n",
    "    evaluator = Evaluator(name=args.dataset)\n",
    "\n",
    "    # get fingerprint feature\n",
    "    X, y = ogb2fp(args.dataset, root=args.dataset_path)\n",
    "\n",
    "    split_idx = dataset.get_idx_split()\n",
    "    train_idx, val_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "    X_train, X_val, X_test = X[train_idx], X[val_idx], X[test_idx]\n",
    "    y_train, y_val, y_test = y[train_idx], y[val_idx], y[test_idx]\n",
    "\n",
    "    val_metrics, test_metrics = [], []\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        print('\\nRun {}'.format(run + 1))\n",
    "\n",
    "        rf = RandomForestClassifier(\n",
    "            min_samples_leaf=args.min_samples_leaf, \n",
    "            n_estimators=args.n_estimators, \n",
    "            n_jobs=-1,\n",
    "            criterion='entropy',\n",
    "            class_weight={0:1, 1:10}\n",
    "            )\n",
    "        rf.fit(X_train, y_train.flatten())\n",
    "\n",
    "        # Calculate probabilities\n",
    "        yh_val = rf.predict_proba(X_val)[:, 1].reshape(-1, 1)\n",
    "        yh_test = rf.predict_proba(X_test)[:, 1].reshape(-1, 1)\n",
    "\n",
    "        val_metric = evaluator.eval({'y_true': y_val, 'y_pred': yh_val})[dataset.eval_metric]\n",
    "        test_metric = evaluator.eval({'y_true': y_test, 'y_pred': yh_test})[dataset.eval_metric]\n",
    "\n",
    "        val_metrics.append(val_metric)\n",
    "        test_metrics.append(test_metric)\n",
    "\n",
    "        print(f'Valid: {val_metric:.4f}, Test: {test_metric:.4f}')\n",
    "        print()\n",
    "\n",
    "    print(f'Valid: {np.mean(val_metrics):.4f} ± {np.std(val_metrics):.4f}')\n",
    "    print(f'Test: {np.mean(test_metrics):.4f} ± {np.std(test_metrics):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='train graph property prediction')\n",
    "parser.add_argument('--dataset', type=str, default='ogbg-molhiv',\n",
    "                    choices=['ogbg-molhiv'])\n",
    "parser.add_argument('--dataset_path', type=str, default='/dev/dataset',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--device', type=int, default=0)\n",
    "parser.add_argument('--min_samples_leaf', type=int, default=2)\n",
    "parser.add_argument('--n_estimators', type=int, default=1000)\n",
    "parser.add_argument('--runs', type=int, default=3)\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)\n",
    "\n",
    "run_graph_pred(args)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
