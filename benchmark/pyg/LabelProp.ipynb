{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Propagation Example (PyG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import EarlyStopping, seed_everything\n",
    "from model import GNN\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LabelPropagation. Note that LabelPropagation has been implemented in PyG, you can import it by `from torch_geometric.nn import LabelPropagation`\n",
    "from gtrick.pyg import LabelPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, task_type):\n",
    "    model.train()\n",
    "    y = data.y\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)\n",
    "    if task_type == 'binary classification':\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            out[train_idx], y.squeeze(1)[train_idx])\n",
    "    elif task_type == 'multiclass classification':\n",
    "        loss = F.cross_entropy(out[train_idx], y.squeeze(1)[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator, eval_metric):\n",
    "    model.eval()\n",
    "\n",
    "    y = data.y\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_metric = evaluator.eval({\n",
    "        'y_true': y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })[eval_metric]\n",
    "    valid_metric = evaluator.eval({\n",
    "        'y_true': y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })[eval_metric]\n",
    "    test_metric = evaluator.eval({\n",
    "        'y_true': y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })[eval_metric]\n",
    "\n",
    "    return train_metric, valid_metric, test_metric, torch.softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_node_pred(args, model, dataset):\n",
    "    device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # dataset = DglNodePropPredDataset(name=args.dataset, root=args.dataset_path)\n",
    "    evaluator = Evaluator(name=args.dataset)\n",
    "\n",
    "    data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    data = data.to(device)\n",
    "\n",
    "    split_idx = dataset.get_idx_split()\n",
    "    train_idx = split_idx['train']\n",
    "\n",
    "    final_test_acc, final_test_acc_lp = [], []\n",
    "    for run in range(args.runs):\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=args.patience, verbose=True, mode='max')\n",
    "\n",
    "        best_test_acc, best_val_acc = 0, 0\n",
    "        best_out = None\n",
    "\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx,\n",
    "                         optimizer, dataset.task_type)\n",
    "            result = test(model, data, split_idx,\n",
    "                          evaluator, dataset.eval_metric)\n",
    "\n",
    "            train_acc, valid_acc, test_acc, out = result\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "            if valid_acc > best_val_acc:\n",
    "                best_val_acc = valid_acc\n",
    "                best_test_acc = test_acc\n",
    "                best_out = out\n",
    "\n",
    "            if early_stopping(valid_acc, model):\n",
    "                break\n",
    "        \n",
    "        # use LabelPropagation to predict test labels and ensemble results\n",
    "        lp = LabelPropagation(args.lp_layers, args.lp_alpah)\n",
    "        yh = lp(data.y, data.adj_t, mask=train_idx)\n",
    "\n",
    "        y_pred = torch.argmax(best_out + yh, dim=-1, keepdim=True)\n",
    "\n",
    "        test_acc_lp = evaluator.eval({\n",
    "            'y_true': data.y[split_idx['test']],\n",
    "            'y_pred': y_pred[split_idx['test']],\n",
    "        })[dataset.eval_metric]\n",
    "\n",
    "        print('Best Test Acc: {:.4f}, Best Test Acc with LP: {:.4f}'.format(best_test_acc, test_acc_lp))\n",
    "        \n",
    "        final_test_acc.append(best_test_acc)\n",
    "        final_test_acc_lp.append(test_acc_lp)\n",
    "    \n",
    "    print('Test Acc: {:.4f}  ± {:.4f}, Test Acc with LP: {:.4f}  ± {:.4f}'.format(np.mean(final_test_acc), np.std(final_test_acc), np.mean(final_test_acc_lp), np.std(final_test_acc_lp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='train node property prediction')\n",
    "parser.add_argument('--dataset', type=str, default='ogbn-arxiv',\n",
    "                    choices=['ogbn-arxiv'])\n",
    "parser.add_argument('--dataset_path', type=str, default='/dev/dataset',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--device', type=int, default=1)\n",
    "parser.add_argument('--log_steps', type=int, default=1)\n",
    "parser.add_argument('--model', type=str, default='sage')\n",
    "parser.add_argument('--num_layers', type=int, default=3)\n",
    "parser.add_argument('--hidden_channels', type=int, default=256)\n",
    "parser.add_argument('--dropout', type=float, default=0.5)\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--epochs', type=int, default=500)\n",
    "parser.add_argument('--runs', type=int, default=3)\n",
    "parser.add_argument('--patience', type=int, default=30)\n",
    "\n",
    "# params for Label Propagation\n",
    "parser.add_argument('--lp_layers', type=int, default=50)\n",
    "parser.add_argument('--lp_alpha', type=float, default=0.9)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)\n",
    "\n",
    "seed_everything(3042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygNodePropPredDataset(name=args.dataset, transform=T.ToSparseTensor(), root=args.dataset_path)\n",
    "data = dataset[0]\n",
    "\n",
    "num_features = data.x.shape[1]\n",
    "\n",
    "model = GNN(num_features, args.hidden_channels,\n",
    "                dataset.num_classes, args.num_layers,\n",
    "                args.dropout, args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_node_pred(args, model, dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
