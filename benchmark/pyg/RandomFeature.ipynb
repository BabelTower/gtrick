{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Feature Example (PyG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "from model import EGCNConv, EGINConv\n",
    "\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "\n",
    "from graph_pred import run_graph_pred\n",
    "\n",
    "from utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random feature\n",
    "from gtrick import random_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGNN(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers,\n",
    "                 dropout, conv_type):\n",
    "\n",
    "        super(EGNN, self).__init__()\n",
    "\n",
    "        self.node_encoder = AtomEncoder(hidden_channels)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # the dim of hidden state plus 1\n",
    "        hidden_channels += 1\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            if conv_type == 'gin':\n",
    "                self.convs.append(\n",
    "                    EGINConv(hidden_channels, self.mol))\n",
    "            elif conv_type == 'gcn':\n",
    "                self.convs.append(\n",
    "                    EGCNConv(hidden_channels, self.mol))\n",
    "\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.out = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for emb in self.node_encoder.atom_embedding_list:\n",
    "            nn.init.xavier_uniform_(emb.weight.data)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            self.convs[i].reset_parameters()\n",
    "            self.bns[i].reset_parameters()\n",
    "\n",
    "        self.out.reset_parameters()\n",
    "\n",
    "    def forward(self, batch_data):\n",
    "        x, edge_index, edge_attr, batch = batch_data.x, batch_data.edge_index, batch_data.edge_attr, batch_data.batch\n",
    "\n",
    "        h = self.node_encoder(x)\n",
    "\n",
    "        # use random_feature to add a random feature (batch_size x 1) to h\n",
    "        h = random_feature(h)\n",
    "\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            h = conv(h, edge_index, edge_attr)\n",
    "            h = self.bns[i](h)\n",
    "            h = F.relu(h)\n",
    "            \n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "\n",
    "        h = self.convs[-1](h, edge_index, edge_attr)\n",
    "\n",
    "        if not self.mol:\n",
    "            h = self.bns[-1](h)\n",
    "\n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "\n",
    "        h = global_mean_pool(h, batch)\n",
    "\n",
    "        h = self.out(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='train graph property prediction')\n",
    "parser.add_argument('--dataset', type=str, default='ogbg-molhiv',\n",
    "                    choices=['ogbg-molhiv', 'ogbg-ppa'])\n",
    "parser.add_argument('--dataset_path', type=str, default='/dev/dataset',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--device', type=int, default=1)\n",
    "parser.add_argument('--log_steps', type=int, default=1)\n",
    "parser.add_argument('--num_layers', type=int, default=4)\n",
    "parser.add_argument('--hidden_channels', type=int, default=300)\n",
    "parser.add_argument('--dropout', type=float, default=0.5)\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--batch_size', type=int, default=64,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--num_workers', type=int, default=0,\n",
    "                    help='number of workers (default: 0)')\n",
    "parser.add_argument('--model', type=str, default='gcn')\n",
    "parser.add_argument('--epochs', type=int, default=500)\n",
    "parser.add_argument('--runs', type=int, default=3)\n",
    "parser.add_argument('--patience', type=int, default=30)\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)\n",
    "\n",
    "seed_everything(3042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygGraphPropPredDataset(\n",
    "name=args.dataset, root=args.dataset_path)\n",
    "\n",
    "model = EGNN(args.hidden_channels,\n",
    "                dataset.num_tasks, args.num_layers,\n",
    "                args.dropout, args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_graph_pred(args, model, dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
